{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-based model for time series data\n",
    "\n",
    "This notebook provides tasks to analyze the flu-trends dataset using a Long Short-Term Memory (LSTM) model.\n",
    "\n",
    "Required Python packages: pandas, numpy, matplotlib, darts, optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Data Preparation\n",
    "\n",
    "\n",
    "- Load the dataset and split in into train/test/validation the same way you did yesterday\n",
    "- Convert the dataset into darts' internal format and plot the data.\n",
    "- Split the dataset into training and test sets and plot the curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Recap - XGBoost Model\n",
    "\n",
    "To familiarize yourself with the new library, you should first look at its documentation. Then, train a XGBoost model on the data set. Just like yesterday. You can either use the default parameters, or you can use the ones you think work best. Compute the same metrics and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import RandomForest\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Training an LSTM-based model\n",
    "\n",
    "We will begin to work with neural networks for time series prediction. One type of neural network is a recurrent neural network (RNN). One of the most popular RNNs is the Long Short-Term Memory (LSTM) network.\n",
    "\n",
    "Your task is to\n",
    "\n",
    "- Use the RNN model from the Darts library.\n",
    "- Train the model on the training set\n",
    "- Make predictions on the test set\n",
    "- Compute the same metrics as in the previous task and compare the results.\n",
    "\n",
    "Unlike tree-based models, neural networks are more sensitive to the scale of the input data. Therefore, you should normalize the data before training the model. For example, you can use a min-max scaler that scales the data to the range [0, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Optuna-based hyperparameter optimization with time series cross-validation\n",
    "\n",
    "Today you will use Optuna to optimize the hyperparameters of the LSTM model. Compared to a grid search-based approach, Optuna is more efficient because it uses a more sophisticated algorithm to search the hyperparameter space. You will also use time series cross-validation to ensure that the model is evaluated on a realistic scenario.\n",
    "\n",
    "Before you start working on this exercise, you should familiarize yourself with [Optuna](https://optuna.org/#key_features). Then you can take a look at the [darts documentation](https://unit8co.github.io/darts/userguide/hyperparameter_optimization.html#hyperparameter-optimization-with-optuna) to see how to use Optuna with darts.\n",
    "\n",
    "While it is not mandatory, we would like you to try to implement a class called RnnOptimization, which will handle the optimization and final training of the LSTM model. This class should have at least four methods:\n",
    "\n",
    "- __init__(self, ...)\n",
    "- objective(self, trial)\n",
    "- optimize(self)\n",
    "- train(self, best_params)\n",
    "\n",
    "Note: Save your optuna study as a sqlite database to avoid losing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Visualizing the Results of Hyperparameter Optimization\n",
    "\n",
    "To understand the optimization process, you should visualize the results. You should create the following plots:\n",
    "\n",
    "- A plot showing the trials and their results\n",
    "- A plot showing the distribution of the results for each hyperparameter\n",
    "- A plot showing the importance of each hyperparameter\n",
    "- A plot showing a 3D surface plot of the two most important hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Final Evaluation\n",
    "\n",
    "Evaluate your model using the test data. Compute metrics (such as RMSE or MAPE) to compare the performance of your LSTM model with the RF and/or XGBoost models. Feel free to repeat the training and evaluation of the ARIMA, Random Forest, and XGBoost models if you want to change the optimization part or have a more consistent approach. Otherwise, you can use the results from the previous days. Visualize the results and discuss them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional tasks\n",
    "\n",
    "Feel free to try anything that you find interesting (ask us for help if you need it). Otherwise, here are some suggestions:\n",
    "\n",
    "- Try adding different features. Systematically analyze the impact of the additional feature on the model performance. Have a look at systematic feature selection: https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "- Have a look at the [Backtesting](https://unit8co.github.io/darts/quickstart/00-quickstart.html#Backtesting:-simulate-historical-forecasting) section of the documentation. Perform an error and residual analysis for one of the models and discuss the results.\n",
    "- If you did not do it yet, try to optimize the number of lags used in the model. Treat it as a hyperparameter.\n",
    "- Does it make a difference if you use the GRU model instead of the LSTM model? Change the parameters accordingly and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
