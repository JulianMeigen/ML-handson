{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulianMeigen/ML-handson/blob/main/notebooks/7.0-SNJMMH-Day7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7e28cad",
      "metadata": {
        "id": "d7e28cad"
      },
      "source": [
        "# Assignment Day 7\n",
        "\n",
        "## Team members:\n",
        "- Samuel Nebgen s6sanebg@uni-bonn.de\n",
        "- Muhammad Humza Arain s27marai@uni-bonn.de\n",
        "- Julian Meigen s82jmeig@uni-bonn.de\n",
        "\n",
        "## 16.09.2025\n",
        "\n",
        "Contributions were made by all team members in around the same amount, either based on discussions or coding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --folder https://drive.google.com/drive/folders/1VESm-JaHEqPJmM23iLW1mEJsuI2mLBdx?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMu2EYgDpjh1",
        "outputId": "25cb8235-d721-4750-f9d4-71602ac50501"
      },
      "id": "LMu2EYgDpjh1",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 1i6W9fI3sGEn6V9xBlt2MxlonZXOTLZjg load-subgraph_doc.ipynb\n",
            "Processing file 1qZpQzFMRzuYQ0xoQJcUNe7CRBMS2mRmz subgraph_hop_1.pt\n",
            "Processing file 1iz_FOBs9k7m9z3lDtRIXzRkd92tL_EK- subgraph.pt\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1i6W9fI3sGEn6V9xBlt2MxlonZXOTLZjg\n",
            "To: /content/ML-HandsOn/load-subgraph_doc.ipynb\n",
            "100% 2.92k/2.92k [00:00<00:00, 15.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qZpQzFMRzuYQ0xoQJcUNe7CRBMS2mRmz\n",
            "To: /content/ML-HandsOn/subgraph_hop_1.pt\n",
            "100% 10.5M/10.5M [00:00<00:00, 59.3MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1iz_FOBs9k7m9z3lDtRIXzRkd92tL_EK-\n",
            "From (redirected): https://drive.google.com/uc?id=1iz_FOBs9k7m9z3lDtRIXzRkd92tL_EK-&confirm=t&uuid=969957c7-9308-4ed3-a29c-57dd17fd67e5\n",
            "To: /content/ML-HandsOn/subgraph.pt\n",
            "100% 1.64G/1.64G [00:26<00:00, 62.7MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivyr61KCaemq",
        "outputId": "69874b11-71a7-4f57-c70e-c96fb318c8e0"
      },
      "id": "Ivyr61KCaemq",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import plotly\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch.nn import Embedding\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv"
      ],
      "metadata": {
        "id": "udctacDr0tZ3"
      },
      "id": "udctacDr0tZ3",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9d575080",
      "metadata": {
        "id": "9d575080"
      },
      "source": [
        "# Task 1 Perform a node labeling task with a Graph ML model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6869181a",
      "metadata": {
        "id": "6869181a"
      },
      "source": [
        "## a) Load the graph dataset (ogbn-proteins) into pytorch-geometric\n",
        "\n",
        "We are directly using a Subgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "\n",
        "path_big = \"/content/ML-HandsOn/subgraph.pt\"\n",
        "path_small = \"/content/ML-HandsOn/subgraph_hop_1.pt\"\n",
        "\n",
        "dataset = torch.load(path_small, weights_only=False)\n",
        "\n",
        "data = dataset[\"graph\"]\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMYvOlq0Oai9",
        "outputId": "e6a75e7e-298a-46b3-b8d8-423ee291cb16"
      },
      "id": "AMYvOlq0Oai9",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(num_nodes=942, edge_index=[2, 200414], edge_attr=[200414, 8], node_species=[942, 1], y=[942, 112])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = to_networkx(data, to_undirected=True)\n",
        "print(G)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLGZSjgMQLwW",
        "outputId": "a616cef8-7dbf-40e7-d754-95c662e649ff"
      },
      "id": "PLGZSjgMQLwW",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph with 942 nodes and 100207 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adb891a2",
      "metadata": {
        "id": "adb891a2"
      },
      "source": [
        "## b) Create a train, val, test split on the nodes or load the masks via pytorch-geometric."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2e4f3ec",
      "metadata": {
        "id": "c2e4f3ec"
      },
      "source": [
        "### i. Create a subgraph if the computation is too expensive."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_nodes = data.num_nodes\n",
        "perm = torch.randperm(num_nodes)\n",
        "\n",
        "train_size = int(0.7 * num_nodes)\n",
        "val_size = int(0.15 * num_nodes)\n",
        "\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "train_mask[perm[:train_size]] = True\n",
        "val_mask[perm[train_size:train_size + val_size]] = True\n",
        "test_mask[perm[train_size + val_size:]] = True\n",
        "\n",
        "data.train_mask = train_mask\n",
        "data.val_mask = val_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "print(data.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOKEF5ISN1y2",
        "outputId": "7d07ecc2-5b2d-4f81-ac33-c0b78fafb940"
      },
      "id": "xOKEF5ISN1y2",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data.y[data.train_mask]))\n",
        "print(len(data.y[data.val_mask]))\n",
        "print(len(data.y[data.test_mask]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4mXk0BvSgBk",
        "outputId": "5a9e8051-f8e7-475a-8f37-509dd7da2197"
      },
      "id": "_4mXk0BvSgBk",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "659\n",
            "141\n",
            "142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9b9d6f",
      "metadata": {
        "id": "be9b9d6f"
      },
      "source": [
        "## c) Initialize the graph with random node embeddings."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_nodes = data.num_nodes\n",
        "embedding_dim = 64\n",
        "x = torch.empty((num_nodes, embedding_dim))  # empty tensor\n",
        "torch.nn.init.xavier_uniform_(x)  # Xavier uniform initialization\n",
        "data.x = x"
      ],
      "metadata": {
        "id": "3i_8zJXRT_P0"
      },
      "id": "3i_8zJXRT_P0",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_idx = np.arange(data.num_nodes)\n",
        "train_idx = torch.tensor(node_idx[data.train_mask.numpy()])\n",
        "test_idx = torch.tensor(node_idx[data.test_mask.numpy()])\n",
        "val_idx = torch.tensor(node_idx[data.val_mask.numpy()])\n",
        "\n",
        "train_subgraph = data.subgraph(train_idx)\n",
        "test_subgraph = data.subgraph(test_idx)\n",
        "val_subgraph = data.subgraph(val_idx)"
      ],
      "metadata": {
        "id": "vXrSAbHZjVpW"
      },
      "id": "vXrSAbHZjVpW",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8ed30d82",
      "metadata": {
        "id": "8ed30d82"
      },
      "source": [
        "## d) Define a graph convolutional neural network class with two layers using pytorch-geometric.."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_nodes, embedding_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(embedding_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, out_dim)\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # apply GCN layers\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "X4YJgz5RV81h"
      },
      "id": "X4YJgz5RV81h",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gcn = GCN(num_nodes=data.num_nodes, embedding_dim=64, hidden_dim=128, out_dim=112)"
      ],
      "metadata": {
        "id": "VCcuHNZ2Xfxr"
      },
      "id": "VCcuHNZ2Xfxr",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "17ea0a7b",
      "metadata": {
        "id": "17ea0a7b"
      },
      "source": [
        "### i. Train your model on the train dataset using an optimizer and a loss function for a multilabel classification task for 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ER9-8rCToKw7",
        "outputId": "2c7287a9-32d7-4f10-8f51-3a89cbf174f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ER9-8rCToKw7",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0, 676,   0,  ..., 755, 937, 938],\n",
              "        [676,   0, 937,  ..., 804, 938, 937]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_subgrap = data.subgraph()"
      ],
      "metadata": {
        "id": "hTkGYWs5nGX1",
        "outputId": "6a5b31cf-0f21-4cd4-b6c5-1fad3bf83c93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hTkGYWs5nGX1",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([942])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(num_nodes=942, edge_index=[2, 200414], edge_attr=[200414, 8], node_species=[942, 1], y=[942, 112], train_mask=[942], val_mask=[942], test_mask=[942], x=[942, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer and loss\n",
        "optimizer = torch.optim.Adam(model_gcn.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 100\n",
        "model_gcn.train()\n",
        "for epoch in range(1, epochs + 1):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_gcn(data.x, train_subgraph.edge_index)  # forward pass\n",
        "    loss = criterion(out, data.y.float())        # multi-label BCE loss\n",
        "    loss.backward()                       # backward pass\n",
        "    optimizer.step()                      # update parameters\n",
        "\n",
        "    if epoch % 10 == 0 or epoch == 1:\n",
        "        print(f\"Epoch {epoch:03d}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "d9QvaRtBiXbF",
        "outputId": "230847d1-d3f9-4e0e-a9bd-762b1755c252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "d9QvaRtBiXbF",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001, Loss: 1.2703\n",
            "Epoch 010, Loss: 1.2705\n",
            "Epoch 020, Loss: 1.2695\n",
            "Epoch 030, Loss: 1.2693\n",
            "Epoch 040, Loss: 1.2693\n",
            "Epoch 050, Loss: 1.2693\n",
            "Epoch 060, Loss: 1.2693\n",
            "Epoch 070, Loss: 1.2693\n",
            "Epoch 080, Loss: 1.2693\n",
            "Epoch 090, Loss: 1.2690\n",
            "Epoch 100, Loss: 1.2690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db51457f",
      "metadata": {
        "id": "db51457f"
      },
      "source": [
        "### ii. Test your model on the test set and evaluate it with accuracy, AUROC, precision, recall and F1 score."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_gcn.eval()\n",
        "with torch.no_grad():\n",
        "    out = model_gcn(data.x, data.edge_index)\n",
        "    predicted_labels = torch.sigmoid(out) > 0.5"
      ],
      "metadata": {
        "id": "5ALJsTVMk2_y"
      },
      "id": "5ALJsTVMk2_y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "999eb937",
      "metadata": {
        "id": "999eb937"
      },
      "source": [
        "## e) Set up a hyperparameter optimization pipeline with nested 5-fold cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0330797",
      "metadata": {
        "id": "c0330797"
      },
      "source": [
        "### i. Familiarize yourself with the hyperparameter optimization package optuna (https://optuna.org/ )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "949b44b6",
      "metadata": {
        "id": "949b44b6"
      },
      "source": [
        "### ii. Integrate the logging package mlflow (https://mlflow.org/) to log your metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06568c19",
      "metadata": {
        "id": "06568c19"
      },
      "source": [
        "### iii. Train and test your models and report the evaluation metrics with mean and std for the nested CV."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdd638c2",
      "metadata": {
        "id": "bdd638c2"
      },
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}