{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulianMeigen/ML-handson/blob/main/notebooks/7.0-SNJMMH-Day7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7e28cad",
      "metadata": {
        "id": "d7e28cad"
      },
      "source": [
        "# Assignment Day 7\n",
        "\n",
        "## Team members:\n",
        "- Samuel Nebgen s6sanebg@uni-bonn.de\n",
        "- Muhammad Humza Arain s27marai@uni-bonn.de\n",
        "- Julian Meigen s82jmeig@uni-bonn.de\n",
        "\n",
        "## 16.09.2025\n",
        "\n",
        "Contributions were made by all team members in around the same amount, either based on discussions or coding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --folder https://drive.google.com/drive/folders/1VESm-JaHEqPJmM23iLW1mEJsuI2mLBdx?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMu2EYgDpjh1",
        "outputId": "cab0d0ca-b199-40a9-8ffe-b46d4dab30c9"
      },
      "id": "LMu2EYgDpjh1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "Ivyr61KCaemq"
      },
      "id": "Ivyr61KCaemq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import plotly\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch.nn import Embedding\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv"
      ],
      "metadata": {
        "id": "udctacDr0tZ3"
      },
      "id": "udctacDr0tZ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9d575080",
      "metadata": {
        "id": "9d575080"
      },
      "source": [
        "# Task 1 Perform a node labeling task with a Graph ML model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6869181a",
      "metadata": {
        "id": "6869181a"
      },
      "source": [
        "## a) Load the graph dataset (ogbn-proteins) into pytorch-geometric\n",
        "\n",
        "We are directly using a Subgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "\n",
        "path_big = \"/content/ML-HandsOn/subgraph.pt\"\n",
        "path_small = \"/content/ML-HandsOn/subgraph_hop_1.pt\"\n",
        "\n",
        "dataset = torch.load(path_big, weights_only=False)\n",
        "\n",
        "dataset = dataset[\"graph\"]\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMYvOlq0Oai9",
        "outputId": "40bcfbe7-86f2-4e73-aff7-240115250c50"
      },
      "id": "AMYvOlq0Oai9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(num_nodes=942, edge_index=[2, 200414], edge_attr=[200414, 8], node_species=[942, 1], y=[942, 112])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = to_networkx(data, to_undirected=True)\n",
        "print(G)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "PLGZSjgMQLwW",
        "outputId": "1916de1f-d593-42ed-d455-0f9fc1ba1c52"
      },
      "id": "PLGZSjgMQLwW",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-506360641.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_networkx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_undirected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/convert.py\u001b[0m in \u001b[0;36mto_networkx\u001b[0;34m(data, node_attrs, edge_attrs, graph_attrs, to_undirected, to_multi, remove_self_loops)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0medge_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_networkx_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_store\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0medge_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(self, u_of_edge, v_of_edge, **attr)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mebunch_to_add\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/networkx/utils/misc.py\u001b[0m in \u001b[0;36m_clear_cache\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_clear_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m     \"\"\"Clear the cache of a graph (currently stores converted graphs).\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adb891a2",
      "metadata": {
        "id": "adb891a2"
      },
      "source": [
        "## b) Create a train, val, test split on the nodes or load the masks via pytorch-geometric."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2e4f3ec",
      "metadata": {
        "id": "c2e4f3ec"
      },
      "source": [
        "### i. Create a subgraph if the computation is too expensive."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_nodes = data.num_nodes\n",
        "perm = torch.randperm(num_nodes)\n",
        "\n",
        "train_size = int(0.8 * num_nodes)\n",
        "val_size = int(0.1 * num_nodes)\n",
        "\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "train_mask[perm[:train_size]] = True\n",
        "val_mask[perm[train_size:train_size + val_size]] = True\n",
        "test_mask[perm[train_size + val_size:]] = True\n",
        "\n",
        "data.train_mask = train_mask\n",
        "data.val_mask = val_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "print(data.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOKEF5ISN1y2",
        "outputId": "f6b5efbd-4077-4421-80a7-cc3bc0773b91"
      },
      "id": "xOKEF5ISN1y2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data.y[data.train_mask]))\n",
        "print(len(data.y[data.val_mask]))\n",
        "print(len(data.y[data.test_mask]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4mXk0BvSgBk",
        "outputId": "16aab80a-7ae9-4999-a1c4-597412549d86"
      },
      "id": "_4mXk0BvSgBk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "753\n",
            "94\n",
            "95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9b9d6f",
      "metadata": {
        "id": "be9b9d6f"
      },
      "source": [
        "## c) Initialize the graph with random node embeddings."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_nodes = data.num_nodes\n",
        "embedding_dim = 112\n",
        "node_embeddings = Embedding(number_nodes, embedding_dim)"
      ],
      "metadata": {
        "id": "3i_8zJXRT_P0"
      },
      "id": "3i_8zJXRT_P0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8ed30d82",
      "metadata": {
        "id": "8ed30d82"
      },
      "source": [
        "## d) Define a graph convolutional neural network class with two layers using pytorch-geometric.."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_nodes, embedding_dim, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.emb = torch.nn.Embedding(num_nodes, embedding_dim)\n",
        "        self.conv1 = GCNConv(embedding_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        # get embeddings for all nodes\n",
        "        x = self.emb.weight\n",
        "        # apply GCN layers\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "X4YJgz5RV81h"
      },
      "id": "X4YJgz5RV81h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gcn = GCN(num_nodes=data.num_nodes, embedding_dim=128, hidden_dim=64, out_dim=121)"
      ],
      "metadata": {
        "id": "VCcuHNZ2Xfxr"
      },
      "id": "VCcuHNZ2Xfxr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "17ea0a7b",
      "metadata": {
        "id": "17ea0a7b"
      },
      "source": [
        "### i. Train your model on the train dataset using an optimizer and a loss function for a multilabel classification task for 100 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rD4wqrk3XQte"
      },
      "id": "rD4wqrk3XQte"
    },
    {
      "cell_type": "markdown",
      "id": "db51457f",
      "metadata": {
        "id": "db51457f"
      },
      "source": [
        "### ii. Test your model on the test set and evaluate it with accuracy, AUROC, precision, recall and F1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "999eb937",
      "metadata": {
        "id": "999eb937"
      },
      "source": [
        "## e) Set up a hyperparameter optimization pipeline with nested 5-fold cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0330797",
      "metadata": {
        "id": "c0330797"
      },
      "source": [
        "### i. Familiarize yourself with the hyperparameter optimization package optuna (https://optuna.org/ )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "949b44b6",
      "metadata": {
        "id": "949b44b6"
      },
      "source": [
        "### ii. Integrate the logging package mlflow (https://mlflow.org/) to log your metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06568c19",
      "metadata": {
        "id": "06568c19"
      },
      "source": [
        "### iii. Train and test your models and report the evaluation metrics with mean and std for the nested CV."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdd638c2",
      "metadata": {
        "id": "bdd638c2"
      },
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}